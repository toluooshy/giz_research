# giz_research

`giz_research` is a Python toolkit for automated analysis of academic papers in PDF format. It extracts text from PDFs, generates detailed analytical summaries using GPT-4.1-mini, and creates a pairwise cross-comparison matrix highlighting relationships and differences between papers. The project is designed to help researchers quickly synthesize and compare multiple studies in a structured and nuanced way.

---

## Features

- **PDF Parsing:** Extracts text from PDFs with page markers and saves clean text files.
- **Analytical Summaries:** Uses GPT to produce detailed JSON summaries for each paper, covering:

  - Empirical status
  - Authors and year
  - Topics and keywords
  - Sector and methods
  - Sample size and data type
  - Novelty, main findings, strengths, limitations
  - Practical relevance

- **Cross-Paper Comparison:** Generates a full pairwise comparison matrix, with each cell containing a full-sentence explanation of the similarities or differences between papers in key dimensions.
- **Structured Outputs:** Produces:

  - `analytical_papers_summary.csv` – per-paper analytical summaries
  - `cross_comparison_matrix.csv` – pairwise comparison matrix

- **Organized Text Storage:** All parsed PDF text is stored in a dedicated `parsed_text/` folder.

---

## Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/your-username/giz_research.git
   cd giz_research
   ```

2. Create and activate a virtual environment:

   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/macOS
   venv\Scripts\activate     # Windows
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

4. Set your OpenAI API key as an environment variable:

   ```bash
   export OPENAI_API_KEY="your_api_key"  # Linux/macOS
   setx OPENAI_API_KEY "your_api_key"     # Windows
   ```

---

## Folder Structure

```
giz_research/
│
├─ papers/                          # Place all PDF files here
├─ parsed_text/                     # Parsed text (.txt) from PDFs is saved here automatically
├─ analytical_papers_summary.csv    # Autogenerated file from run_analysis.py
├─ cross_comparison_matrix.csv      # Autogenerated file from run_analysis.py
├─ run_analysis.py                  # Main script to process papers
└─ README.md
```

---

## Usage

Run the main analysis script:

```bash
python analysis.py
```

The script will:

1. Parse all PDFs in the `papers/` folder.
2. Save the text from each PDF in `parsed_text/`.
3. Generate a detailed analytical summary for each paper and save it as `analytical_papers_summary.csv`.
4. Generate a pairwise cross-comparison matrix with full-sentence explanations and save it as `cross_comparison_matrix.csv`.

---

## Output Files

- **`parsed_text/`**: Contains a `.txt` file for each PDF with all extracted text.
- **`analytical_papers_summary.csv`**: Each row corresponds to a paper, with columns representing key analytical dimensions in full sentences.
- **`cross_comparison_matrix.csv`**: A square matrix where each cell explains the relationship between two papers in a concise full sentence.

---

## Notes

- The first run may be slow for large numbers of PDFs because each paper is analyzed individually.
- Ensure you have a valid OpenAI API key with sufficient quota.
- If using many papers, consider optimizing pairwise comparisons to reduce API calls.

---

## License

MIT License – see `LICENSE` file for details.
